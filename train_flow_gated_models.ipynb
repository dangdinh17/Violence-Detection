{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023143,
     "end_time": "2024-08-25T08:48:37.350557",
     "exception": false,
     "start_time": "2024-08-25T08:48:37.327414",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T08:48:37.398114Z",
     "iopub.status.busy": "2024-08-25T08:48:37.397371Z",
     "iopub.status.idle": "2024-08-25T08:48:37.601183Z",
     "shell.execute_reply": "2024-08-25T08:48:37.600523Z",
     "shell.execute_reply.started": "2024-08-25T08:14:35.524381Z"
    },
    "papermill": {
     "duration": 0.229746,
     "end_time": "2024-08-25T08:48:37.601379",
     "exception": false,
     "start_time": "2024-08-25T08:48:37.371633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transform Video to .npy Format\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T08:48:37.653922Z",
     "iopub.status.busy": "2024-08-25T08:48:37.653223Z",
     "iopub.status.idle": "2024-08-25T08:48:37.656228Z",
     "shell.execute_reply": "2024-08-25T08:48:37.655532Z",
     "shell.execute_reply.started": "2024-08-25T08:14:35.919551Z"
    },
    "papermill": {
     "duration": 0.033737,
     "end_time": "2024-08-25T08:48:37.656352",
     "exception": false,
     "start_time": "2024-08-25T08:48:37.622615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getOpticalFlow(video):\n",
    "    \"\"\"Calculate dense optical flow of input video\n",
    "    Args:\n",
    "        video: the input video with shape of [frames,height,width,channel]. dtype=np.array\n",
    "    Returns:\n",
    "        flows_x: the optical flow at x-axis, with the shape of [frames,height,width,channel]\n",
    "        flows_y: the optical flow at y-axis, with the shape of [frames,height,width,channel]\n",
    "    \"\"\"\n",
    "    # initialize the list of optical flows\n",
    "    gray_video = []\n",
    "    for i in range(len(video)):\n",
    "        img = cv2.cvtColor(video[i], cv2.COLOR_RGB2GRAY)\n",
    "        gray_video.append(np.reshape(img,(224,224,1)))\n",
    "\n",
    "    flows = []\n",
    "    for i in range(0,len(video)-1):\n",
    "        # calculate optical flow between each pair of frames\n",
    "        flow = cv2.calcOpticalFlowFarneback(gray_video[i], gray_video[i+1], None, 0.5, 3, 15, 3, 5, 1.2, cv2.OPTFLOW_FARNEBACK_GAUSSIAN)\n",
    "        # subtract the mean in order to eliminate the movement of camera\n",
    "        flow[..., 0] -= np.mean(flow[..., 0])\n",
    "        flow[..., 1] -= np.mean(flow[..., 1])\n",
    "        # normalize each component in optical flow\n",
    "        flow[..., 0] = cv2.normalize(flow[..., 0],None,0,255,cv2.NORM_MINMAX)\n",
    "        flow[..., 1] = cv2.normalize(flow[..., 1],None,0,255,cv2.NORM_MINMAX)\n",
    "        # Add into list \n",
    "        flows.append(flow)\n",
    "        \n",
    "    # Padding the last frame as empty array\n",
    "    flows.append(np.zeros((224,224,2)))\n",
    "      \n",
    "    return np.array(flows, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T08:48:37.706790Z",
     "iopub.status.busy": "2024-08-25T08:48:37.706179Z",
     "iopub.status.idle": "2024-08-25T08:48:37.709040Z",
     "shell.execute_reply": "2024-08-25T08:48:37.708424Z",
     "shell.execute_reply.started": "2024-08-25T08:14:36.560146Z"
    },
    "papermill": {
     "duration": 0.031837,
     "end_time": "2024-08-25T08:48:37.709160",
     "exception": false,
     "start_time": "2024-08-25T08:48:37.677323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Video2Npy(file_path, resize=(224,224)):\n",
    "    \"\"\"Load video and tansfer it into .npy format\n",
    "    Args:\n",
    "        file_path: the path of video file\n",
    "        resize: the target resolution of output video\n",
    "    Returns:\n",
    "        frames: gray-scale video\n",
    "        flows: magnitude video of optical flows \n",
    "    \"\"\"\n",
    "    # Load video\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    # Get number of frames\n",
    "    len_frames = int(cap.get(7))\n",
    "    # Extract frames from video\n",
    "    try:\n",
    "        frames = []\n",
    "        for i in range(len_frames-1):\n",
    "            _, frame = cap.read()\n",
    "            frame = cv2.resize(frame,resize, interpolation=cv2.INTER_AREA)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = np.reshape(frame, (224,224,3))\n",
    "            frames.append(frame)   \n",
    "    except:\n",
    "        print(\"Error: \", file_path, len_frames,i)\n",
    "    finally:\n",
    "        frames = np.array(frames)\n",
    "        cap.release()\n",
    "            \n",
    "    # Get the optical flow of video\n",
    "    flows = getOpticalFlow(frames)\n",
    "    \n",
    "    result = np.zeros((len(flows),224,224,5))\n",
    "    result[...,:3] = frames\n",
    "    result[...,3:] = flows\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T08:48:37.757654Z",
     "iopub.status.busy": "2024-08-25T08:48:37.756895Z",
     "iopub.status.idle": "2024-08-25T08:48:37.759418Z",
     "shell.execute_reply": "2024-08-25T08:48:37.758836Z",
     "shell.execute_reply.started": "2024-08-25T08:14:36.963774Z"
    },
    "papermill": {
     "duration": 0.02932,
     "end_time": "2024-08-25T08:48:37.759543",
     "exception": false,
     "start_time": "2024-08-25T08:48:37.730223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Save2Npy(videos, save_dir):\n",
    "    \"\"\"Transfer all the videos and save them into specified directory\n",
    "    Args:\n",
    "        videos: list of target videos with pathlib Path.\n",
    "        save_dir: destination folder of output .npy files\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    # List the files\n",
    "    \n",
    "    for path in tqdm(videos):\n",
    "        # Split video name\n",
    "        name = os.path.basename(path)\n",
    "        # Get dest \n",
    "        save_path = os.path.join(save_dir, name[:-4]+'.npy')\n",
    "        # os.path.join(save_dir, name + '.npy')\n",
    "        # Load and preprocess video\n",
    "        data = Video2Npy(file_path=path, resize=(224,224))\n",
    "        data = np.uint8(data)\n",
    "        # Save as .npy file\n",
    "        np.save(save_path, data)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T08:48:37.807036Z",
     "iopub.status.busy": "2024-08-25T08:48:37.806419Z",
     "iopub.status.idle": "2024-08-25T09:17:23.480609Z",
     "shell.execute_reply": "2024-08-25T09:17:23.481239Z",
     "shell.execute_reply.started": "2024-08-25T08:14:37.239622Z"
    },
    "papermill": {
     "duration": 1725.70084,
     "end_time": "2024-08-25T09:17:23.481431",
     "exception": false,
     "start_time": "2024-08-25T08:48:37.780591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m         file_paths \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(srcsubsub, file) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(srcsubsub)]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#         process_videos(srcsubsub, sub, subsub)\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m         \u001b[43mSave2Npy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_path\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msub\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msubsub\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDone \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msub\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubsub\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m data...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 20\u001b[0m, in \u001b[0;36mSave2Npy\u001b[1;34m(videos, save_dir)\u001b[0m\n\u001b[0;32m     17\u001b[0m save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_dir, name[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# os.path.join(save_dir, name + '.npy')\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Load and preprocess video\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mVideo2Npy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39muint8(data)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Save as .npy file\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 30\u001b[0m, in \u001b[0;36mVideo2Npy\u001b[1;34m(file_path, resize)\u001b[0m\n\u001b[0;32m     27\u001b[0m     cap\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Get the optical flow of video\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m flows \u001b[38;5;241m=\u001b[39m \u001b[43mgetOpticalFlow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(flows),\u001b[38;5;241m224\u001b[39m,\u001b[38;5;241m224\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m     33\u001b[0m result[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,:\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m=\u001b[39m frames\n",
      "Cell \u001b[1;32mIn[2], line 18\u001b[0m, in \u001b[0;36mgetOpticalFlow\u001b[1;34m(video)\u001b[0m\n\u001b[0;32m     15\u001b[0m flows \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;28mlen\u001b[39m(video)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# calculate optical flow between each pair of frames\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m     flow \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalcOpticalFlowFarneback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgray_video\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgray_video\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOPTFLOW_FARNEBACK_GAUSSIAN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# subtract the mean in order to eliminate the movement of camera\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     flow[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(flow[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "source_path = 'dataset'\n",
    "target_path = './dest'\n",
    "for sub in os.listdir(source_path):\n",
    "    srcsub = os.path.join(source_path, sub)\n",
    "#     os.makedirs(output_sub, exist_ok = True)\n",
    "    for subsub in os.listdir(srcsub):\n",
    "        srcsubsub = os.path.join(srcsub, subsub)\n",
    "        file_paths = [os.path.join(srcsubsub, file) for file in os.listdir(srcsubsub)]\n",
    "#         process_videos(srcsubsub, sub, subsub)\n",
    "        Save2Npy(file_paths, target_path+f'/{sub}/{subsub}')\n",
    "        print(f'Done {sub} {subsub} data...')\n",
    "print(f'Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T09:17:23.886386Z",
     "iopub.status.busy": "2024-08-25T09:17:23.885596Z",
     "iopub.status.idle": "2024-08-25T09:17:23.888401Z",
     "shell.execute_reply": "2024-08-25T09:17:23.887920Z",
     "shell.execute_reply.started": "2024-08-25T08:43:13.764117Z"
    },
    "papermill": {
     "duration": 0.192551,
     "end_time": "2024-08-25T09:17:23.888533",
     "exception": false,
     "start_time": "2024-08-25T09:17:23.695982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.204597,
     "end_time": "2024-08-25T09:17:24.289065",
     "exception": false,
     "start_time": "2024-08-25T09:17:24.084468",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Build Data Loader\n",
    "\n",
    "> Based on this article: \n",
    "> https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "\n",
    "Only rewrite these functions:\n",
    "\n",
    "- def \\__len__(self):\n",
    "- def \\__getitem__(self, index):\n",
    "- def on_epoch_end(self):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T09:17:24.663162Z",
     "iopub.status.busy": "2024-08-25T09:17:24.662436Z",
     "iopub.status.idle": "2024-08-25T09:17:29.362847Z",
     "shell.execute_reply": "2024-08-25T09:17:29.362285Z",
     "shell.execute_reply.started": "2024-08-25T08:43:13.769829Z"
    },
    "papermill": {
     "duration": 4.889739,
     "end_time": "2024-08-25T09:17:29.363000",
     "exception": false,
     "start_time": "2024-08-25T09:17:24.473261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T09:17:29.771966Z",
     "iopub.status.busy": "2024-08-25T09:17:29.748034Z",
     "iopub.status.idle": "2024-08-25T09:17:29.774237Z",
     "shell.execute_reply": "2024-08-25T09:17:29.774692Z",
     "shell.execute_reply.started": "2024-08-25T08:43:13.981613Z"
    },
    "papermill": {
     "duration": 0.226416,
     "end_time": "2024-08-25T09:17:29.774864",
     "exception": false,
     "start_time": "2024-08-25T09:17:29.548448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence, to_categorical\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    \"\"\"Data Generator inherited from keras.utils.Sequence\n",
    "    Args: \n",
    "        directory: the path of data set, and each sub-folder will be assigned to one class\n",
    "        batch_size: the number of data points in each batch\n",
    "        shuffle: whether to shuffle the data per epoch\n",
    "    Note:\n",
    "        If you want to load file with other data format, please fix the method of \"load_data\" as you want\n",
    "    \"\"\"\n",
    "    def __init__(self, directory, batch_size=1, shuffle=True, data_augmentation=True):\n",
    "        # Initialize the params\n",
    "        self.batch_size = batch_size\n",
    "        self.directory = directory\n",
    "        self.shuffle = shuffle\n",
    "        self.data_aug = data_augmentation\n",
    "        # Load all the save_path of files, and create a dictionary that save the pair of \"data:label\"\n",
    "        self.X_path, self.Y_dict = self.search_data() \n",
    "        # Print basic statistics information\n",
    "        self.print_stats()\n",
    "        return None\n",
    "    \n",
    "    def __len__(self):\n",
    "        # calculate the iterations of each epoch\n",
    "        steps_per_epoch = np.ceil(len(self.X_path) / float(self.batch_size))\n",
    "        return int(steps_per_epoch)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Get the data of each batch\n",
    "        \n",
    "        \"\"\"\n",
    "        # get the indexs of each batch\n",
    "        batch_indexs = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # using batch_indexs to get path of current batch\n",
    "        batch_path = [self.X_path[k] for k in batch_indexs]\n",
    "        # get batch data\n",
    "        batch_x, batch_y = self.data_generation(batch_path)\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"\n",
    "        shuffle the data at each end of epoch\n",
    "        \n",
    "        \"\"\"\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "        \n",
    "    def search_data(self):\n",
    "        \"\"\"\n",
    "        1 - Lists subfolders.\n",
    "        2 - takes all the names of npy files in th paths\n",
    "        3 - make the one-hot encoded labels.\n",
    "        \"\"\"\n",
    "        X_path = []\n",
    "        Y_dict = {}\n",
    "        # list all kinds of sub-folders\n",
    "        self.dirs = sorted(os.listdir(self.directory))\n",
    "        one_hots = to_categorical(range(len(self.dirs)))\n",
    "        for i,folder in enumerate(self.dirs):\n",
    "            folder_path = os.path.join(self.directory,folder)\n",
    "            for file in os.listdir(folder_path):\n",
    "                file_path = os.path.join(folder_path,file)\n",
    "                # append the each file path, and keep its label  \n",
    "                X_path.append(file_path)\n",
    "                Y_dict[file_path] = one_hots[i]\n",
    "        return X_path, Y_dict\n",
    "    \n",
    "    def print_stats(self):\n",
    "        \"\"\"\n",
    "        calculate basic information\n",
    "        \n",
    "        \"\"\"\n",
    "        self.n_files = len(self.X_path)\n",
    "        self.n_classes = len(self.dirs)\n",
    "        self.indexes = np.arange(len(self.X_path))\n",
    "        np.random.shuffle(self.indexes)\n",
    "        # Output states\n",
    "        print(\"Found {} files belonging to {} classes.\".format(self.n_files,self.n_classes))\n",
    "        for i,label in enumerate(self.dirs):\n",
    "            print('%10s : '%(label),i)\n",
    "        return None\n",
    "    \n",
    "    def data_generation(self, batch_path):\n",
    "        \"\"\"\"\n",
    "        load data into memory, you can change the np.load to any method you want\n",
    "        \n",
    "        \"\"\"\n",
    "        batch_x = [self.load_data(x) for x in batch_path]\n",
    "        batch_y = [self.Y_dict[x] for x in batch_path]\n",
    "        # transfer the data format and take one-hot coding for labels\n",
    "        batch_x = np.array(batch_x)\n",
    "        batch_y = np.array(batch_y)\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "    def normalize(self, data):\n",
    "        mean = np.mean(data)\n",
    "        std = np.std(data)\n",
    "        return (data-mean) / std\n",
    "    \n",
    "    def load_data(self, path):\n",
    "        # load the processed .npy files which have 5 channels (1-3 for RGB, 4-5 for optical flows)\n",
    "        data = np.load(path, mmap_mode='r')\n",
    "        data = np.float32(data)\n",
    "        # sampling 64 frames uniformly from the entire video\n",
    "        data = self.uniform_sampling(video=data, target_frames=64)\n",
    "        # whether to utilize the data augmentation\n",
    "        if  self.data_aug:\n",
    "            data[...,:3] = self.color_jitter(data[...,:3])\n",
    "            data = self.random_flip(data, prob=0.5)\n",
    "        # normalize rgb images and optical flows, respectively\n",
    "        data[...,:3] = self.normalize(data[...,:3])\n",
    "        data[...,3:] = self.normalize(data[...,3:])\n",
    "        return data\n",
    "    \n",
    "    def uniform_sampling(self, video, target_frames=64):\n",
    "        \"\"\"\n",
    "        1 - Count the number of frames.\n",
    "        2 - calculate the interval = num_frames/target_frames\n",
    "        3 - Take frames from video after skipping interval frames in between.\n",
    "        \n",
    "        \"\"\"\n",
    "        # get total frames of input video and calculate sampling interval \n",
    "        len_frames = int(len(video))\n",
    "        interval = int(np.ceil(len_frames/target_frames))\n",
    "        # init empty list for sampled video and \n",
    "        sampled_video = []\n",
    "        for i in range(0,len_frames,interval):\n",
    "            sampled_video.append(video[i])     \n",
    "        # calculate numer of padded frames and fix it \n",
    "        num_pad = target_frames - len(sampled_video)\n",
    "        padding = []\n",
    "        if num_pad>0:\n",
    "            for i in range(-num_pad,0):\n",
    "                try: \n",
    "                    padding.append(video[i])\n",
    "                except:\n",
    "                    padding.append(video[0])\n",
    "            sampled_video += padding     \n",
    "        # get sampled video\n",
    "        return np.array(sampled_video, dtype=np.float32)\n",
    "    \n",
    "    def random_flip(self, video, prob):\n",
    "        \"\"\"\n",
    "        # Augmentation\n",
    "        flips all the video frames\n",
    "        \"\"\"\n",
    "        s = np.random.rand()\n",
    "        if s < prob:\n",
    "            video = np.flip(m=video, axis=2)\n",
    "        return video\n",
    "    \n",
    "    def random_clip(self, video, target_frames=64):\n",
    "        \"\"\"\n",
    "        # Augmentation\n",
    "        randomly clips some part of video.\n",
    "        \"\"\"\n",
    "        start_point = np.random.randint(len(video)-target_frames)\n",
    "        return video[start_point:start_point+target_frames]\n",
    "    \n",
    "    def dynamic_crop(self, video):\n",
    "        \"\"\"\n",
    "        # Augmentation\n",
    "        \n",
    "        \"\"\"\n",
    "        # extract layer of optical flow from video\n",
    "        opt_flows = video[...,3]\n",
    "        # sum of optical flow magnitude of individual frame\n",
    "        magnitude = np.sum(opt_flows, axis=0)\n",
    "        # filter slight noise by threshold \n",
    "        thresh = np.mean(magnitude)\n",
    "        magnitude[magnitude<thresh] = 0\n",
    "        # calculate center of gravity of magnitude map and adding 0.001 to avoid empty value\n",
    "        x_pdf = np.sum(magnitude, axis=1) + 0.001\n",
    "        y_pdf = np.sum(magnitude, axis=0) + 0.001\n",
    "        # normalize PDF of x and y so that the sum of probs = 1\n",
    "        x_pdf /= np.sum(x_pdf)\n",
    "        y_pdf /= np.sum(y_pdf)\n",
    "        # randomly choose some candidates for x and y \n",
    "        x_points = np.random.choice(a=np.arange(224), size=10, replace=True, p=x_pdf)\n",
    "        y_points = np.random.choice(a=np.arange(224), size=10, replace=True, p=y_pdf)\n",
    "        # get the mean of x and y coordinates for better robustness\n",
    "        x = int(np.mean(x_points))\n",
    "        y = int(np.mean(y_points))\n",
    "        # avoid to beyond boundaries of array\n",
    "        x = max(56,min(x,167))\n",
    "        y = max(56,min(y,167))\n",
    "        # get cropped video \n",
    "        return video[:,x-56:x+56,y-56:y+56,:]  \n",
    "    \n",
    "    def color_jitter(self,video):\n",
    "        \"\"\"\n",
    "        # Augmentation\n",
    "        \n",
    "        \"\"\"\n",
    "        # range of s-component: 0-1\n",
    "        # range of v component: 0-255\n",
    "        s_jitter = np.random.uniform(-0.2,0.2)\n",
    "        v_jitter = np.random.uniform(-30,30)\n",
    "        for i in range(len(video)):\n",
    "            hsv = cv2.cvtColor(video[i], cv2.COLOR_RGB2HSV)\n",
    "            s = hsv[...,1] + s_jitter\n",
    "            v = hsv[...,2] + v_jitter\n",
    "            s[s<0] = 0\n",
    "            s[s>1] = 1\n",
    "            v[v<0] = 0\n",
    "            v[v>255] = 255\n",
    "            hsv[...,1] = s\n",
    "            hsv[...,2] = v\n",
    "            video[i] = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "        return video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.186946,
     "end_time": "2024-08-25T09:17:30.560191",
     "exception": false,
     "start_time": "2024-08-25T09:17:30.373245",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.181895,
     "end_time": "2024-08-25T09:17:30.925051",
     "exception": false,
     "start_time": "2024-08-25T09:17:30.743156",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# The model Architecture:\n",
    "\n",
    "The network consists of 2 parallel nets:\n",
    "\n",
    "- RGB input\n",
    "- Optical flow input\n",
    "\n",
    "the output of these networks are then multiplied to keep the RGB features which there is movement in sequence of frames. (take a look at figure 5 - cropping strategy)\n",
    "\n",
    "# Cropping strategy:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T09:17:31.320415Z",
     "iopub.status.busy": "2024-08-25T09:17:31.315247Z",
     "iopub.status.idle": "2024-08-25T09:17:35.063620Z",
     "shell.execute_reply": "2024-08-25T09:17:35.062691Z",
     "shell.execute_reply.started": "2024-08-25T08:43:14.106855Z"
    },
    "papermill": {
     "duration": 3.953761,
     "end_time": "2024-08-25T09:17:35.063882",
     "exception": false,
     "start_time": "2024-08-25T09:17:31.110121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:192: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Input, Dense, Flatten, Conv3D, MaxPooling3D, Dropout, Multiply, Input, Lambda,\n",
    "                                     BatchNormalization)\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from models.flow_gated_models import FlowGatedModels\n",
    "model = FlowGatedModels().build_model()\n",
    "sgd = SGD(learning_rate=0.005, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.185196,
     "end_time": "2024-08-25T09:17:35.478598",
     "exception": false,
     "start_time": "2024-08-25T09:17:35.293402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Compiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.183259,
     "end_time": "2024-08-25T09:17:35.845886",
     "exception": false,
     "start_time": "2024-08-25T09:17:35.662627",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Set Callbacks\n",
    "- Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T09:17:36.225375Z",
     "iopub.status.busy": "2024-08-25T09:17:36.224734Z",
     "iopub.status.idle": "2024-08-25T09:17:36.227634Z",
     "shell.execute_reply": "2024-08-25T09:17:36.227029Z",
     "shell.execute_reply.started": "2024-08-25T08:44:04.728857Z"
    },
    "papermill": {
     "duration": 0.197791,
     "end_time": "2024-08-25T09:17:36.227778",
     "exception": false,
     "start_time": "2024-08-25T09:17:36.029987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "import keras\n",
    "\n",
    "def scheduler(epoch):\n",
    "    if epoch % 10 == 0 and epoch != 0:\n",
    "        lr = K.get_value(model.optimizer.lr)\n",
    "        K.set_value(model.optimizer.lr, lr * 0.7)\n",
    "    return K.get_value(model.optimizer.lr)\n",
    "\n",
    "reduce_lr = LearningRateScheduler(scheduler)\n",
    "\n",
    "class MyCbk(keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, model):\n",
    "         self.model_to_save = model\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.model_to_save.save('Logs/model_at_epoch_%d.h5' % (epoch+1))\n",
    "\n",
    "check_point = MyCbk(model)\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_model.weights.h5',\n",
    "    monitor='val_accuracy',  # Theo dõi độ chính xác trên tập validation\n",
    "    verbose=1,               # Hiển thị thông tin khi mô hình được lưu\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,# Chỉ lưu mô hình có độ chính xác tốt nhất\n",
    "    mode='max'               # Lưu mô hình khi giá trị 'val_accuracy' lớn nhất\n",
    ")\n",
    "\n",
    "filename = 'Logs/ours_log.csv'\n",
    "\n",
    "csv_logger = CSVLogger(filename, separator=',', append=True)\n",
    "\n",
    "callbacks_list = [check_point, checkpoint, csv_logger, reduce_lr]\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "callbacks_list.append(early_stopping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T09:17:36.610205Z",
     "iopub.status.busy": "2024-08-25T09:17:36.609600Z",
     "iopub.status.idle": "2024-08-25T09:17:38.682697Z",
     "shell.execute_reply": "2024-08-25T09:17:38.682103Z",
     "shell.execute_reply.started": "2024-08-25T08:44:06.784360Z"
    },
    "papermill": {
     "duration": 2.266393,
     "end_time": "2024-08-25T09:17:38.682856",
     "exception": false,
     "start_time": "2024-08-25T09:17:36.416463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file Logs already exists.\n",
      "'touch' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!mkdir Logs\n",
    "!touch Logs/outs_log.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T09:17:39.060360Z",
     "iopub.status.busy": "2024-08-25T09:17:39.059359Z",
     "iopub.status.idle": "2024-08-25T10:59:56.296301Z",
     "shell.execute_reply": "2024-08-25T10:59:56.295591Z",
     "shell.execute_reply.started": "2024-08-25T08:43:16.903118Z"
    },
    "papermill": {
     "duration": 6137.432571,
     "end_time": "2024-08-25T10:59:56.299579",
     "exception": false,
     "start_time": "2024-08-25T09:17:38.867008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 files belonging to 2 classes.\n",
      "     Fight :  0\n",
      "  NonFight :  1\n",
      "Found 50 files belonging to 2 classes.\n",
      "     Fight :  0\n",
      "  NonFight :  1\n",
      "Found 249 files belonging to 2 classes.\n",
      "     Fight :  0\n",
      "  NonFight :  1\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_8256\\2368292429.py\", line 16, in <module>\n",
      "    hist = model.fit(\n",
      "           ^^^^^^^^^^\n",
      "  File \"c:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"c:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 119, in error_handler\n",
      "    filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: TensorFlowTrainer.fit() got an unexpected keyword argument 'workers'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2168, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1454, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1345, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1192, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1179, in get_records\n",
      "    res = list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\stack_data\\core.py\", line 597, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "  File \"c:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\stack_data\\utils.py\", line 83, in collapse_repeated\n",
      "    yield from map(mapper, original_group)\n",
      "  File \"c:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\stack_data\\core.py\", line 587, in mapper\n",
      "    return cls(f, options)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\stack_data\\core.py\", line 551, in __init__\n",
      "    self.executing = Source.executing(frame_or_tb)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\executing\\executing.py\", line 283, in executing\n",
      "    assert_(new_stmts <= stmts)\n",
      "  File \"c:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\executing\\executing.py\", line 80, in assert_\n",
      "    raise AssertionError(str(message))\n",
      "AssertionError\n"
     ]
    }
   ],
   "source": [
    "num_epochs  = 40\n",
    "num_workers = 16\n",
    "batch_size  = 8\n",
    "\n",
    "train_generator = DataGenerator(directory='./dest/train', \n",
    "                                batch_size=batch_size, \n",
    "                                data_augmentation=True)\n",
    "\n",
    "val_generator = DataGenerator(directory='./dest/val',\n",
    "                              batch_size=batch_size, \n",
    "                              data_augmentation=False)\n",
    "test_generator = DataGenerator(directory='./dest/test',\n",
    "                              batch_size=batch_size, \n",
    "                              data_augmentation=False)\n",
    "# with strategy.scope():\n",
    "hist = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1,\n",
    "    epochs=num_epochs,\n",
    "    workers=num_workers,\n",
    "    max_queue_size=4,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_steps=len(val_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T10:59:58.019521Z",
     "iopub.status.busy": "2024-08-25T10:59:58.018668Z",
     "iopub.status.idle": "2024-08-25T10:59:58.830813Z",
     "shell.execute_reply": "2024-08-25T10:59:58.831313Z"
    },
    "papermill": {
     "duration": 1.684312,
     "end_time": "2024-08-25T10:59:58.831481",
     "exception": false,
     "start_time": "2024-08-25T10:59:57.147169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(hist.history['loss'], label='Training Loss')\n",
    "plt.plot(hist.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Vẽ đồ thị accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(hist.history.get('accuracy', hist.history.get('acc')), label='Training Accuracy')\n",
    "plt.plot(hist.history.get('val_accuracy', hist.history.get('val_acc')), label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T11:00:00.564389Z",
     "iopub.status.busy": "2024-08-25T11:00:00.563552Z",
     "iopub.status.idle": "2024-08-25T11:00:29.848746Z",
     "shell.execute_reply": "2024-08-25T11:00:29.848077Z",
     "shell.execute_reply.started": "2024-08-25T08:46:37.235933Z"
    },
    "papermill": {
     "duration": 30.164213,
     "end_time": "2024-08-25T11:00:29.848909",
     "exception": false,
     "start_time": "2024-08-25T10:59:59.684696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator, verbose=2)\n",
    "    print(f\"Test loss: {test_loss}\")\n",
    "    print(f\"Test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T11:00:31.583030Z",
     "iopub.status.busy": "2024-08-25T11:00:31.582192Z",
     "iopub.status.idle": "2024-08-25T11:00:32.115640Z",
     "shell.execute_reply": "2024-08-25T11:00:32.115045Z",
     "shell.execute_reply.started": "2024-08-25T08:46:27.100609Z"
    },
    "papermill": {
     "duration": 1.385604,
     "end_time": "2024-08-25T11:00:32.115829",
     "exception": false,
     "start_time": "2024-08-25T11:00:30.730225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.load_weights('weights/best_models_fgm.h5')\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "print('done')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.848726,
     "end_time": "2024-08-25T11:00:33.811070",
     "exception": false,
     "start_time": "2024-08-25T11:00:32.962344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5585558,
     "sourceId": 9234406,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5590327,
     "sourceId": 9241624,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30068,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7925.409689,
   "end_time": "2024-08-25T11:00:37.776913",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-25T08:48:32.367224",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
