{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c7e665",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-25T03:31:10.244933Z",
     "iopub.status.busy": "2024-08-25T03:31:10.244647Z",
     "iopub.status.idle": "2024-08-25T03:36:04.079787Z",
     "shell.execute_reply": "2024-08-25T03:36:04.078745Z"
    },
    "papermill": {
     "duration": 293.841662,
     "end_time": "2024-08-25T03:36:04.082884",
     "exception": false,
     "start_time": "2024-08-25T03:31:10.241222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Function to process videos and save augmented images\n",
    "def process_videos(path, subdir, subsubdir):\n",
    "    output_dir = os.path.join(output, subdir,subsubdir)\n",
    "    os.makedirs(output_dir, exist_ok=True)                   \n",
    "    for video_file in tqdm(os.listdir(path), desc=f\"Processing {subdir} {subsubdir} videos\", unit = 'vid'):\n",
    "        cap = cv2.VideoCapture(os.path.join(path, video_file))\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Failed to open video file {video_file}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        frame_count = 0\n",
    "        video_name = os.path.basename(video_file)[:-4]\n",
    "        while cap.isOpened():\n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "#                 print(f\"Finished processing {video_file} from {subdir} set.\")\n",
    "                break\n",
    "\n",
    "            # Convert the BGR image to RGB.\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            # Process the image and find pose landmarks.\n",
    "            output_path = os.path.join(output_dir, f\"{video_name}_frame_{frame_count}.jpg\")\n",
    "#             print(output_path)\n",
    "            cv2.imwrite(output_path, image)\n",
    "            frame_count += 1\n",
    "        cap.release()\n",
    "\n",
    "    print(f\"Finished processing all videos in {subdir} {subsubdir} videos\")\n",
    "\n",
    "\n",
    "# Process videos from each split with data augmentation\n",
    "source_dir = './dataset'\n",
    "output = './dest'\n",
    "for sub in os.listdir(source_dir):\n",
    "    srcsub = os.path.join(source_dir, sub)\n",
    "#     os.makedirs(output_sub, exist_ok = True)\n",
    "    for subsub in os.listdir(srcsub):\n",
    "        srcsubsub = os.path.join(srcsub, subsub)\n",
    "        process_videos(srcsubsub, sub, subsub)\n",
    "print(\"Finished processing all videos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ab3382",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-25T03:36:20.695749Z",
     "iopub.status.busy": "2024-08-25T03:36:20.694918Z",
     "iopub.status.idle": "2024-08-25T06:29:25.947497Z",
     "shell.execute_reply": "2024-08-25T06:29:25.946523Z"
    },
    "papermill": {
     "duration": 10385.300681,
     "end_time": "2024-08-25T06:29:25.949672",
     "exception": false,
     "start_time": "2024-08-25T03:36:20.648991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "os.environ['WANDB_MODE'] = 'disabled'\n",
    "# Load a model\n",
    "# model = YOLO(\"yolov8n.pt\")  # load an official model\n",
    "model = YOLO(\"yolov8n-cls.pt\")  # load a custom model\n",
    "\n",
    "# Validate the model\n",
    "results = model.train(data=\"./dest\", epochs=40, device = [0, 1],  imgsz=224, batch = 512) # no arguments needed, dataset and settings remembered\n",
    "\n",
    "metrics = model.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.top1  # top1 accuracy\n",
    "metrics.top5  # top5 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cbe71e",
   "metadata": {
    "papermill": {
     "duration": 0.427196,
     "end_time": "2024-08-25T06:29:26.812508",
     "exception": false,
     "start_time": "2024-08-25T06:29:26.385312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5585558,
     "sourceId": 9234406,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10703.03865,
   "end_time": "2024-08-25T06:29:30.254936",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-25T03:31:07.216286",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
